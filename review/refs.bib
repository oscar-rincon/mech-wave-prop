
@article{seron-1990,
author = {Serón, F. J. and Sanz, F. J. and Kindelán, M. and Badal, J. I.},
title = {Finite-element method for elastic wave propagation},
journal = {Communications in Applied Numerical Methods},
volume = {6},
number = {5},
pages = {359-368},
doi = {https://doi.org/10.1002/cnm.1630060505},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cnm.1630060505},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cnm.1630060505},
abstract = {Abstract The object of this work is to analyse the computational aspects of the finite-element method for the elastic wave equations. The necessary numerical techniques are analysed from the point of view of accuracy, performance and storage requirements when implemented in scalar and vector processors with large storage capacity. The method is implemented on an IBM 3090 with vector facility. For this implementation we consider five different time integration schemes (explicit and implicit central difference, Houbolt, constant average acceleration and Wilson), and in the implicit case, both direct (Gaussian decomposition) and iterative (successive over-relaxation, Jacobi semi-iterative, Jacobi conjugate gradient) sparse linear systems solvers. These solvers are taken from the ITPACK2C and ESSL libraries using in each case the adequate representation scheme; skyline, row-wise and compressed diagonal. From our results it is concluded that constant average acceleration and explicit central difference are the most adequate integration methods and Jacobi conjugate gradient is the most efficient solver.},
year = {1990}
}

@Article{app13031312,
AUTHOR = {Liu, Siqin and Zhou, Zhusheng and Zeng, Weizu},
TITLE = {Simulation of Elastic Wave Propagation Based on Meshless Generalized Finite Difference Method with Uniform Random Nodes and Damping Boundary Condition},
JOURNAL = {Applied Sciences},
VOLUME = {13},
YEAR = {2023},
NUMBER = {3},
ARTICLE-NUMBER = {1312},
URL = {https://www.mdpi.com/2076-3417/13/3/1312},
ISSN = {2076-3417},
ABSTRACT = {When the grid-based finite difference (FD) method is used for elastic wavefield forward modeling, it is inevitable that the grid divisions will be inconsistent with the actual velocity interface, resulting in problems related to the stepped grid diffraction and inaccurate travel time of reflected waves. The generalized finite difference method (GFDM), which is based on the Taylor series expansion and weighted least square fitting, solves these problems. The partial derivative of the unknown parameters in the differential equation is represented by the linear combination of the function values of adjacent nodes. In this study, the Poisson disk node generation algorithm and the centroid Voronoi node adjustment algorithm were combined to obtain an even and random node distribution. The generated nodes fit the internal boundary more accurately for model discretization, without the presence of diffracted waves caused by the stepped grid. To avoid the instability caused by the introduction of boundary conditions, a Cerjan damping boundary condition was proposed for boundary reflection processing. The test results generated by the different models showed that the generalized finite difference method can effectively solve the problems related to inaccurate travel time of reflection waves and stepped grid diffraction.},
DOI = {10.3390/app13031312}
}


@book{Aki,
   abstract = {Second edition. "First paperback impression; corrected printing"--Title page verso},
   author = {Keiiti Aki and Paul G. Richards},
   isbn = {9781891389634},
   pages = {700},
   year ={2002},
   title = {Quantitative seismology},
}


@book{Achenbach1973,
   abstract = {The propagation of mechanical disturbances in solids is of interest in many branches of the physical scienses and engineering. This book aims to present an account of the theory of wave propagation in elastic solids. The material is arranged to present an exposition of the basic concepts of mechanical wave propagation within a one-dimensional setting and a discussion of formal aspects of elastodynamic theory in three dimensions, followed by chapters expounding on typical wave propagation phenomena, such as radiation, reflection, refraction, propagation in waveguides, and diffraction. The treatment necessarily involves considerable mathematical analysis. The pertinent mathematical techniques are, however, discussed at some length. Introduction -- One-dimensional motion of an elastic continuum -- The linearized theory of elasticity -- Elastodynamic theory -- Elastic waves in an unbound medium -- Plane harmonic waves in elastic half-spaces -- Harmonic waves in waveguides -- Forced motions of a half-space -- Transient waves in layers and rods -- Diffraction of waves by a slit -- Thermal and viscoelastic effects, and effects of anisotrophy and non-linearity.},
   author = {J. D. Achenbach},
   isbn = {0720423503},
   pages = {425},
   publisher = {North-Holland Pub. Co},
   title = {Wave propagation in elastic solids,},
   year = {1973},
}

@book{pujol,
   author = {Jose Pujol},
   publisher = {cambridge university press},
   title = {Elastic Wave Propagation
and Generation in
Seismology},
   year = {2003},
}

@article{Liu2023,
   abstract = {When the grid-based finite difference (FD) method is used for elastic wavefield forward modeling, it is inevitable that the grid divisions will be inconsistent with the actual velocity interface, resulting in problems related to the stepped grid diffraction and inaccurate travel time of reflected waves. The generalized finite difference method (GFDM), which is based on the Taylor series expansion and weighted least square fitting, solves these problems. The partial derivative of the unknown parameters in the differential equation is represented by the linear combination of the function values of adjacent nodes. In this study, the Poisson disk node generation algorithm and the centroid Voronoi node adjustment algorithm were combined to obtain an even and random node distribution. The generated nodes fit the internal boundary more accurately for model discretization, without the presence of diffracted waves caused by the stepped grid. To avoid the instability caused by the introduction of boundary conditions, a Cerjan damping boundary condition was proposed for boundary reflection processing. The test results generated by the different models showed that the generalized finite difference method can effectively solve the problems related to inaccurate travel time of reflection waves and stepped grid diffraction.},
   author = {Siqin Liu and Zhusheng Zhou and Weizu Zeng},
   doi = {10.3390/app13031312},
   issn = {20763417},
   issue = {3},
   journal = {Applied Sciences (Switzerland)},
   keywords = {Cerjan damping boundary condition,centroid Voronoi,elastic wave modeling,generalized finite difference method (GFDM)},
   month = {2},
   publisher = {MDPI},
   title = {Simulation of Elastic Wave Propagation Based on Meshless Generalized Finite Difference Method with Uniform Random Nodes and Damping Boundary Condition},
   volume = {13},
   year = {2023},
}


@article{Ursula,
   author = {Ursula Iturrarán-Viveros and Francisco J. Sánchez-Sesma},
   doi = {10.1007/978-3-030-10475-7_6-1},
   issn = {1871756X},
   journal = {Encyclopedia of Earth Sciences Series},
   publisher = {Springer Science and Business Media B.V.},
   title = {Seismic Wave Propagation in Real Media: Numerical Modeling Approaches},
   year = {2020},
}

@book{Carcione2002,
   author = {José Carcione},
   title = {Wave Propagation in Anisotropic, Anelastic, Porous and Electromagnetic Media},
   year = {2002},
}

@incollection{Moczo,
title = {The Finite-Difference Time-Domain Method for Modeling of Seismic Wave Propagation},
editor = {Ru-Shan Wu and Valerie Maupin and Renata Dmowska},
series = {Advances in Geophysics},
publisher = {Elsevier},
volume = {48},
pages = {421-516},
year = {2007},
booktitle = {Advances in Wave Propagation in Heterogenous Earth},
issn = {0065-2687},
doi = {https://doi.org/10.1016/S0065-2687(06)48008-0},
url = {https://www.sciencedirect.com/science/article/pii/S0065268706480080},
author = {Peter Moczo and Johan O.A. Robertsson and Leo Eisner},
keywords = {Anisotropy, Attenuation, Earthquake motion, Earthquake source dynamics, Finite-difference method, Free surface, Non-reflecting boundaries, Numerical modeling, Optimally accurate operators, Seismic waves},
abstract = {We present a review of the recent development in finite-difference time-domain modeling of seismic wave propagation and earthquake motion. The finite-difference method is a robust numerical method applicable to structurally complex media. Due to its relative accuracy and computational efficiency it is the dominant method in modeling earthquake motion and it also is becoming increasingly more important in the seismic industry and for structural modeling. We first introduce basic formulations and properties of the finite-difference schemes including promising recent advances. Then we address important topics as material discontinuities, realistic attenuation, anisotropy, the planar free surface boundary condition, free-surface topography, wavefield excitation (including earthquake source dynamics), non-reflecting boundaries, and memory optimization and parallelization.}
}

@book{Chapman2004,
   abstract = {1. Introduction -- 2. Basic wave propagation -- 3. Transforms -- 4. Review of continuum mechanics and elastic waves -- 5. Asymptotic ray theory -- 6. Rays at an interface -- 7. Differential systems for stratified media -- 8. Inverse transforms for stratified media -- 9. Canonical signals -- 10. Generalizations of ray theory.},
   author = {Chris H. Chapman},
   isbn = {052181538X},
   pages = {608},
   publisher = {Cambridge University Press},
   title = {Fundamentals of seismic wave propagation},
   year = {2004},
}

@misc{Seriani2020,
   abstract = {The numerical modeling of mechanical waves is currently a fundamental tool for the study and investigation of their propagation in media with heterogeneous physical properties and/or complex geometry, as, in these cases, analytical methods are usually not applicable. These techniques are used in geophysics (geophysical interpretation, subsoil imaging, development of new methods of exploration), seismology (study of earthquakes, regional and global seismology, accurate calculation of synthetic seismograms), in the development of new methods for ultrasonic diagnostics in materials science (non-destructive methods) and medicine (acoustic tomography). In this paper we present a review of numerical methods that have been developed and are currently used. In particular we review the key concepts and pioneering ideas behind finite-difference methods, pseudospectral methods, finite-volume methods, Galerkin continuous and discontinuous finite-element methods (classical or based on spectral interpolation), and still others such as physics-compatible, and multiscale methods. We focus on their formulations in time domain along with the main temporal discretization schemes. We present the theory and implementation for some of these methods. Moreover, their computational characteristics are evaluated in order to aid the choice of the method for each practical situation.},
   author = {G. Seriani and S. P. Oliveira},
   doi = {10.1007/s40766-020-00009-0},
   issn = {18269850},
   issue = {9},
   journal = {Rivista del Nuovo Cimento},
   month = {9},
   pages = {459-514},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Numerical modeling of mechanical wave propagation},
   volume = {43},
   year = {2020},
}

@article{guarin-2023,
   abstract = {There is an increasing interest in the study of metamaterials and periodic materials across disciplines. These are anisotropic and their properties present directionality. For example, the wave speed depends on the propagation direction. Furthermore, they are heterogeneous, and their directionality depends on their spectra. Common approaches to describe anisotropy have been used in the large-wavelength approximation corresponding to static properties. Here we present an anisotropy measure based on the dynamic behavior. It receives dispersion surfaces from Bloch analyses and outputs a curve/surface with bulk directionality encoded on it. We present results for elastodynamics, but it is applicable to other phenomena.},
   author = {Nicolás Guarín-Zapata and Camilo Valencia and Juan Gomez},
   doi = {10.1080/15376494.2023.2226958},
   issn = {15376532},
   journal = {Mechanics of Advanced Materials and Structures},
   keywords = {Bloch analysis,Periodic material,anisotropy,dispersion relation,phononic crystal},
   publisher = {Taylor and Francis Ltd.},
   title = {Analysis of the directionality on periodic materials},
   year = {2023},
}

@misc{FEniCS,
   author = {Hans Petter Langtangen and Anders Logg},
   title = {Solving PDEs in Python The FEniCS Tutorial I},
   url = {http://www.springer.com/series/13548},
 year = {2016},
}

@software{solidspy,
 title = {SolidsPy: 2D-Finite Element Analysis with Python},
 version = {1.1.0},
 author = {Guarín-Zapata, Nicolás and Gómez, Juan},
 year = 2023,
 keywords = {Python, Finite elements, Scientific computing, Computational mechanics},
 abstract = {SolidsPy is a simple finite element analysis code for 2D elasticity
 problems. The code uses as input simple-to-create text files defining a model
 in terms of nodal, element, material and load data.},
 url = {https://github.com/AppliedMechanics-EAFIT/SolidsPy},
 doi = {https://doi.org/10.5281/zenodo.7694030}
}


@article{Padovani,
author = {Padovani, E. and Priolo, E. and Seriane, G.},
title = {Low and High Order Finite Element Method: Experience in Seismic Modeling},
journal = {Journal of Computational Acoustics},
volume = {02},
number = {04},
pages = {371-422},
year = {1994},
doi = {10.1142/S0218396X94000233},
URL ={https://doi.org/10.1142/S0218396X94000233},
}

@book{Tarantola,
author = {Tarantola, Albert},
title = {Inverse Problem Theory and Methods for Model Parameter Estimation},
publisher = {Society for Industrial and Applied Mathematics},
year = {2005},
doi = {10.1137/1.9780898717921},
address = {},
edition   = {},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9780898717921},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9780898717921}
}

@book{Igel2017,
   author = {Heiner Igel},
   publisher = {Oxford University Press},
   title = {Computational seismology: a practical introduction},
   year = {2017},
}


@book{Schuster,
   author = {Gerard Schuster},
   publisher = {Society of Exploration Geophysicists,},
   title = {Seismic Inversion},
   year = {2017},
}

@book{Moczo2014,
   abstract = {Among all the numerical methods in seismology, the finite-difference (FD) technique provides the best balance of accuracy and computational efficiency. This book offers a comprehensive introduction to FD and its applications to earthquake motion. Using a systematic tutorial approach, the book requires only undergraduate degree-level mathematics and provides a user-friendly explanation of the relevant theory. It explains FD schemes for solving wave equations and elastodynamic equations of motion in heterogeneous media, and provides an introduction to the rheology of viscoelastic and elastoplastic media. It also presents an advanced FD time-domain method for efficient numerical simulations of earthquake ground motion in realistic complex models of local surface sedimentary structures. Accompanied by a suite of online resources to help put the theory into practice, this is a vital resource for professionals and academic researchers using numerical seismological techniques, and graduate students in earthquake seismology, computational and numerical modelling, and applied mathematics. A systematic tutorial introduction to the finite-difference (FD) numerical modelling technique for professionals, academic researchers, and graduate students in seismology. Cover; Half title; Epigraph; Title; Copyright; Dedication; Contents; Acknowledgements; Selected symbols; Abbreviations; Mathematical notation; Greek symbols; Latin symbols; 1 Introduction; Part I Mathematical-physical model; 2 Basic mathematical-physical model; 2.1 Medium; 2.2 Governing equation: equation of motion; 2.2.1 Strong form; 2.2.2 Weak form; 2.2.3 Integral strong form; 2.2.4 Concluding remark; 2.3 Constitutive law: stress-strain relation; 2.3.1 Elastic continuum; 2.3.2 Viscoelastic continuum; 2.4 Strong-form formulations of equations; 2.4.1 Displacement-stress formulation 2.4.2 Displacement formulation2.4.3 Displacement-velocity-stress formulation; 2.4.4 Velocity-stress formulation; 2.5 Boundary conditions; 2.5.1 Free surface; 2.5.2 Welded material interface; 2.6 Initial conditions; 2.7 Wavefield source (wavefield excitation); 3 Rheological models of a continuum; 3.1 Basic rheological models; 3.1.1 Hooke elastic solid; 3.1.2 Newton viscous liquid; 3.1.3 Saint-Venant plastic solid; 3.2 Combined rheological models; 3.3 Viscoelastic continuum and its rheological models; 3.3.1 Stress-strain and strain-stress relations in a viscoelastic continuum 3.3.1.1 Preliminary considerations3.3.1.2 General theory in 1D; 3.3.2 Maxwell and Kelvin-Voigt bodies; 3.3.3 Zener body (standard linear solid); 3.3.4 Phase velocity in elastic and viscoelastic continua; 3.3.5 Measure of dissipation and attenuation in a viscoelastic continuum; 3.3.6 Attenuation in a Zener body; 3.3.7 Generalized Zener body (GZB); 3.3.8 Generalized Maxwell body (GMB-EK); 3.3.9 Equivalence of GZB and GMB-EK; 3.3.10 Anelastic functions (memory variables); 3.3.11 Anelastic coefficients and unrelaxed modulus; 3.3.12 Attenuation and phase velocity in GMB-EK/GZB continuum 3.3.13 Stress-strain relation in 3D3.4 Elastoplastic continuum; 3.4.1 Simplest elastoplastic bodies; 3.4.2 Iwan elastoplastic model for hysteretic stress-strain behaviour; 3.4.2.1 Preliminary considerations; 3.4.2.2 Iwan model; 3.4.2.3 Iwan model and Masing rules; 3.4.2.4 Determination of parameters for Iwan model; 3.4.2.5 Note on damping; 3.4.2.6 Concluding remark; 4 Earthquake source; 4.1 Dynamic model of an earthquake source; 4.1.1 Boundary conditions for dynamic shear faulting; 4.1.2 Friction law; 4.1.2.1 Linear slip-weakening friction law; 4.1.2.2 Rate- and state-dependent friction law 4.2 Kinematic model of an earthquake source4.2.1 Point source; 4.2.2 Finite-fault kinematic source; Part II The finite-difference method; 5 Time-domain numerical methods; 5.1 Introduction; 5.2 Fourier pseudo-spectral method; 5.3 Spectral element method; 5.4 Spectral discontinuous Galerkin scheme with ADER time integration; 5.5 Hybrid methods; 6 Brief introduction to the finite-difference method; 6.1 Space-time grids; 6.1.1 Cartesian grid; 6.1.2 Uniform, nonuniform and discontinuous grids; 6.1.3 Structured and unstructured grids; 6.1.4 Space-time locations of field variables},
   author = {Peter Moczo and Jozef Kristek and Martin Gális},
   isbn = {9781107028814},
   pages = {365},
   title = {The Finite-Difference Modelling of Earthquake Motions : Waves and Ruptures},
   year = {2014},
}




@article{Zhou2021,
   author = {Hongyu Zhou and Yang Liu and Jing Wang},
   doi = {10.29382/eqs-2021},
   journal = {Earthquake Science},
   keywords = {Courant-Friedrichs-Lewy numbers,acoustic wave equation,finite-difference,stability condition,vari-able length},
   pages = {123-236},
   title = {Acoustic finite-difference modeling beyond conventi-onal Courant-Friedrichs-Lewy stability limit: Approach based on variable-length temporal and spatial operators},
   volume = {34},
   year = {2021},
}
@misc{Virieux1986,
   abstract = {I present a finite-difference method for modeling P-SV wave propagation in heterogeneous media. This is an extension of the method I previously proposed for modeling SH-wave propagation by using velocity and stress in a discrete grid. The two components of the velocity cannot be defined at the same node for a complete staggered grid: the stability condition and the P-wave phase velocity dispersion curve do not depend on the Poisson's ratio, while the S-wave phase velocity dispersion curve behavior is rather insensitive to the Poisson's ratio. Therefore, the same code used for elastic media can be used for liquid media, where S-wave ve-INTRODUCTION},
   author = {Jean Virieux},
   title = {p-sv wave propagation in heterogeneous media: Velocity-stress finite-difference method},
   url = {http://library.seg.org/},
   year = {1986},
}

@article{Raissi2019,
   abstract = {We introduce physics-informed neural networks – neural networks that are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear partial differential equations. In this work, we present our developments in the context of solving two main classes of problems: data-driven solution and data-driven discovery of partial differential equations. Depending on the nature and arrangement of the available data, we devise two distinct types of algorithms, namely continuous time and discrete time models. The first type of models forms a new family of data-efficient spatio-temporal function approximators, while the latter type allows the use of arbitrarily accurate implicit Runge–Kutta time stepping schemes with unlimited number of stages. The effectiveness of the proposed framework is demonstrated through a collection of classical problems in fluids, quantum mechanics, reaction–diffusion systems, and the propagation of nonlinear shallow-water waves.},
   author = {M. Raissi and P. Perdikaris and G. E. Karniadakis},
   doi = {10.1016/J.JCP.2018.10.045},
   issn = {0021-9991},
   journal = {Journal of Computational Physics},
   keywords = {Data-driven scientific computing,Machine learning,Nonlinear dynamics,Predictive modeling,Runge–Kutta methods},
   month = {2},
   pages = {686-707},
   publisher = {Academic Press},
   title = {Physics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations},
   volume = {378},
   year = {2019},
}
@article{Song2022,
   abstract = {Wavefield reconstruction inversion (WRI) formulates a PDE-constrained optimization problem to reduce cycle skipping in full-waveform inversion (FWI). WRI is often implemented by solving for the frequency-domain representation of the wavefield using the finite-difference method. The approach requires matrix inversions and affords limited flexibility to accommodate irregular model geometries. On the other hand, the physics-informed neural network (PINN) uses the underlying physical laws as loss functions to train the neural network (NN) to provide flexible continuous functional approximations of the solutions without matrix inversions. By including a data-constrained term in the loss function, the trained NN can reconstruct a wavefield that simultaneously fits the recorded data and satisfies the Helmholtz equation for a given initial velocity model. Using the predicted wavefields, we rely on a small-size NN to predict the velocity using the reconstructed wavefield. In this velocity prediction NN, spatial coordinates are used as input data to the network, and the scattered Helmholtz equation is used to define the loss function. After we train this network, we are able to predict the velocity in the domain of interest. We develop this PINN-based WRI method and demonstrate its potential using a part of the Sigsbee2A model and a modified Marmousi model. The results show that the PINN-based WRI is able to invert for a reasonable velocity with very limited iterations and frequencies, which can be used in a subsequent FWI application.},
   author = {Chao Song and Tariq A. Alkhalifah},
   doi = {10.1109/TGRS.2021.3123122},
   issn = {15580644},
   journal = {IEEE Transactions on Geoscience and Remote Sensing},
   keywords = {Frequency-domain,Helmholtz equation,full-waveform inversion (FWI),physics-informed neural network (PINN),wavefield reconstruction inversion (WRI)},
   publisher = {Institute of Electrical and Electronics Engineers Inc.},
   title = {Wavefield Reconstruction Inversion via Physics-Informed Neural Networks},
   volume = {60},
   year = {2022},
}


@article{liu_simulation_2023,
	title = {Simulation of {Elastic} {Wave} {Propagation} {Based} on {Meshless} {Generalized} {Finite} {Difference} {Method} with {Uniform} {Random} {Nodes} and {Damping} {Boundary} {Condition}},
	volume = {13},
	doi = {10.3390/app13031312},
	abstract = {When the grid-based finite difference (FD) method is used for elastic wavefield forward modeling, it is inevitable that the grid divisions will be inconsistent with the actual velocity interface, resulting in problems related to the stepped grid diffraction and inaccurate travel time of reflected waves. The generalized finite difference method (GFDM), which is based on the Taylor series expansion and weighted least square fitting, solves these problems. The partial derivative of the unknown parameters in the differential equation is represented by the linear combination of the function values of adjacent nodes. In this study, the Poisson disk node generation algorithm and the centroid Voronoi node adjustment algorithm were combined to obtain an even and random node distribution. The generated nodes fit the internal boundary more accurately for model discretization, without the presence of diffracted waves caused by the stepped grid. To avoid the instability caused by the introduction of boundary conditions, a Cerjan damping boundary condition was proposed for boundary reflection processing. The test results generated by the different models showed that the generalized finite difference method can effectively solve the problems related to inaccurate travel time of reflection waves and stepped grid diffraction.},
	number = {3},
	journal = {Applied Sciences (Switzerland)},
	author = {Liu, Siqin and Zhou, Zhusheng and Zeng, Weizu},
	month = feb,
	year = {2023},
	note = {Publisher: MDPI},
	keywords = {centroid Voronoi, Cerjan damping boundary condition, elastic wave modeling, generalized finite difference method (GFDM)},
	file = {Liu et al. - 2023 - Simulation of Elastic Wave Propagation Based on Me.pdf:C\:\\Users\\osrin\\Zotero\\storage\\BCTSY2MD\\Liu et al. - 2023 - Simulation of Elastic Wave Propagation Based on Me.pdf:application/pdf},
}


@article{rasht-behesht_physics-informed_2022,
	title = {Physics-{Informed} {Neural} {Networks} ({PINNs}) for {Wave} {Propagation} and {Full} {Waveform} {Inversions}},
	volume = {127},
	copyright = {© 2022. American Geophysical Union. All Rights Reserved.},
	issn = {2169-9356},
	url ={https://onlinelibrary.wiley.com/doi/abs/10.1029/2021JB023120},
	doi = {10.1029/2021JB023120},
	abstract = {We propose a new approach to the solution of the wave propagation and full waveform inversions (FWIs) based on a recent advance in deep learning called physics-informed neural networks (PINNs). In this study, we present an algorithm for PINNs applied to the acoustic wave equation and test the method with both forward models and FWI case studies. These synthetic case studies are designed to explore the ability of PINNs to handle varying degrees of structural complexity using both teleseismic plane waves and seismic point sources. PINNs' meshless formalism allows for a flexible implementation of the wave equation and different types of boundary conditions. For instance, our models demonstrate that PINN automatically satisfies absorbing boundary conditions, a serious computational challenge for common wave propagation solvers. Furthermore, a priori knowledge of the subsurface structure can be seamlessly encoded in PINNs' formulation. We find that the current state-of-the-art PINNs provide good results for the forward model, even though spectral element or finite difference methods are more efficient and accurate. More importantly, our results demonstrate that PINNs yield excellent results for inversions on all cases considered and with limited computational complexity. We discuss the current limitations of the method with complex velocity models as well as strategies to overcome these challenges. Using PINNs as a geophysical inversion solver offers exciting perspectives, not only for the full waveform seismic inversions, but also when dealing with other geophysical datasets (e.g., MT, gravity) as well as joint inversions because of its robust framework and simple implementation.},
	language = {en},
	number = {5},
	urldate = {2024-01-30},
	journal = {Journal of Geophysical Research: Solid Earth},
	author = {Rasht-Behesht, Majid and Huber, Christian and Shukla, Khemraj and Karniadakis, George Em},
	year = {2022},
	keywords = {acoustic wave propagation, deep learning, full waveform inversion, physics-informed neural networks},
	pages = {e2021JB023120},
	annote = {e2021JB023120 2021JB023120},
	file = {Snapshot:/home/orincon/snap/zotero-snap/common/Zotero/storage/KXLU7S7Y/2021JB023120.html:text/html;Submitted Version:/home/orincon/snap/zotero-snap/common/Zotero/storage/FSESZLFX/Rasht-Behesht et al. - 2022 - Physics-Informed Neural Networks (PINNs) for Wave .pdf:application/pdf},
}



@article{moseley_deep_2020,
	title = {Deep learning for fast simulation of seismic waves in complex media},
	volume = {11},
	issn = {1869-9510},
	url = {https://se.copernicus.org/articles/11/1527/2020/},
	doi = {10.5194/se-11-1527-2020},
	abstract = {The simulation of seismic waves is a core task in many geophysical applications. Numerical methods such as finite difference (FD) modelling and spectral element methods (SEMs) are the most popular techniques for simulating seismic waves, but disadvantages such as their computational cost prohibit their use for many tasks. In this work, we investigate the potential of deep learning for aiding seismic simulation in the solid Earth sciences. We present two deep neural networks which are able to simulate the seismic response at multiple locations in horizontally layered and faulted 2-D acoustic media an order of magnitude faster than traditional finite difference modelling. The first network is able to simulate the seismic response in horizontally layered media and uses a WaveNet network architecture design. The second network is significantly more general than the first and is able to simulate the seismic response in faulted media with arbitrary layers, fault properties and an arbitrary location of the seismic source on the surface of the media, using a conditional autoencoder design. We test the sensitivity of the accuracy of both networks to different network hyperparameters and show that the WaveNet network can be retrained to carry out fast seismic inversion in the same media. We find that are there are challenges when extending our methods to more complex, elastic and 3-D Earth models; for example, the accuracy of both networks is reduced when they are tested on models outside of their training distribution. We discuss further research directions which could address these challenges and potentially yield useful tools for practical simulation tasks.},
	language = {English},
	number = {4},
	urldate = {2024-01-30},
	journal = {Solid Earth},
	author = {Moseley, Ben and Nissen-Meyer, Tarje and Markham, Andrew},
	month = aug,
	year = {2020},
	note = {Publisher: Copernicus GmbH},
	pages = {1527--1549},
	file = {Full Text PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/FDLLGK6R/Moseley et al. - 2020 - Deep learning for fast simulation of seismic waves.pdf:application/pdf},
}


@phdthesis{moseley_physics-informed_2022,
	title = {Physics-informed machine learning: from concepts to real-world applications},
	shorttitle = {Physics-informed machine learning},
	url = {https://ora.ox.ac.uk/objects/uuid:b790477c-771f-4926-99c6-d2f9d248cb23},
	abstract = {{\textless}p{\textgreater}Machine learning (ML) has caused a fundamental shift in how we practice science, with many now placing learning from data at the focal point of their research. As the complexity of the scientific problems we want to study increases, and the amount of data generated by today's scientific experiments grows, ML is helping to automate, accelerate and enhance traditional workflows.{\textless}/p{\textgreater} {\textless}p{\textgreater}Emerging at the forefront of this revolution is a field called scientific machine learning (SciML). The central goal of SciML is to more tightly combine existing scientific understanding with ML, generating powerful ML algorithms which are informed by our prior knowledge.{\textless}/p{\textgreater} {\textless}p{\textgreater}A plethora of approaches exist for incorporating scientific principles into ML and expectations are rising for SciML to address some of the biggest challenges in science. However, the field is burgeoning and many questions are still arising. A major one is whether SciML approaches can scale to more complex, real-world problems. Much SciML research is at a proof-of-concept stage, where techniques are validated on simplified, toy problems. Yet, understanding how well they scale to more complex problems is essential for them to become widely applicable.{\textless}/p{\textgreater} {\textless}p{\textgreater}This question is of central focus in this thesis. Firstly, multiple different physics-informed ML approaches are designed for three complex, real-world, domain-specific case studies taken from the fields of lunar science and geophysics, and their performance and scalability is assessed. Secondly, the scalability of physics-informed neural networks, a popular and general SciML approach, for solving differential equations with large domains and high frequency solutions is evaluated and improved. Common observations across these studies are discussed, and significant advantages and underlying limitations are identified, highlighting the importance of designing scalable SciML techniques.{\textless}/p{\textgreater}},
	language = {English},
	urldate = {2024-01-30},
	school = {University of Oxford},
	author = {Moseley, B.},
	year = {2022},
	file = {Full Text PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/QKQMLP4U/Moseley - 2022 - Physics-informed machine learning from concepts t.pdf:application/pdf},
}



@article{Robertsson,
	address = {Cham},
	title = {Numerical {Methods}, {Finite} {Difference}},
	isbn = {978-3-030-10475-7},
	url = {http://link.springer.com/10.1007/978-3-030-10475-7_135-1},
	language = {en},
	urldate = {2024-02-01},
	booktitle = {Encyclopedia of {Solid} {Earth} {Geophysics}},
	publisher = {Springer International Publishing},
	author = {Robertsson, Johan O. A. and Blanch, Joakim O.},
	editor = {Gupta, Harsh K.},
	year = {2020},
	doi = {10.1007/978-3-030-10475-7_135-1},
	note = {Series Title: Encyclopedia of Earth Sciences Series},
	pages = {1--9},
	file = {Robertsson and Blanch - 2020 - Numerical Methods, Finite Difference.pdf:/home/orincon/snap/zotero-snap/common/Zotero/storage/Q4CWX7TB/Robertsson and Blanch - 2020 - Numerical Methods, Finite Difference.pdf:application/pdf},
}


@article{karimpouli_physics_2020,
	title = {Physics informed machine learning: {Seismic} wave equation},
	volume = {11},
	issn = {1674-9871},
	shorttitle = {Physics informed machine learning},
	url = {https://www.sciencedirect.com/science/article/pii/S1674987120301717},
	doi = {10.1016/j.gsf.2020.07.007},
	abstract = {Similar to many fields of sciences, recent deep learning advances have been applied extensively in geosciences for both small- and large-scale problems. However, the necessity of using large training data and the ‘black box’ nature of learning have limited them in practice and difficult to interpret. Furthermore, including the governing equations and physical facts in such methods is also another challenge, which entails either ignoring the physics or simplifying them using unrealistic data. To address such issues, physics informed machine learning methods have been developed which can integrate the governing physics law into the learning process. In this work, a 1-dimensional (1D) time-dependent seismic wave equation is considered and solved using two methods, namely Gaussian process (GP) and physics informed neural networks. We show that these meshless methods are trained by smaller amount of data and can predict the solution of the equation with even high accuracy. They are also capable of inverting any parameter involved in the governing equation such as wave velocity in our case. Results show that the GP can predict the solution of the seismic wave equation with a lower level of error, while our developed neural network is more accurate for velocity (P- and S-wave) and density inversion.},
	number = {6},
	urldate = {2024-02-01},
	journal = {Geoscience Frontiers},
	author = {Karimpouli, Sadegh and Tahmasebi, Pejman},
	month = nov,
	year = {2020},
	keywords = {Gaussian process (GP), Optimization, Physics informed machine learning (PIML), Seismic wave},
	pages = {1993--2001},
	file = {Karimpouli and Tahmasebi - 2020 - Physics informed machine learning Seismic wave eq.pdf:/home/orincon/snap/zotero-snap/common/Zotero/storage/TLCZRAWN/Karimpouli and Tahmasebi - 2020 - Physics informed machine learning Seismic wave eq.pdf:application/pdf;ScienceDirect Snapshot:/home/orincon/snap/zotero-snap/common/Zotero/storage/L8R35MEI/S1674987120301717.html:text/html},
}


@article{karniadakis_physics-informed_2021,
	title = {Physics-informed machine learning},
	volume = {3},
	copyright = {2021 Springer Nature Limited},
	issn = {2522-5820},
	url = {https://www.nature.com/articles/s42254-021-00314-5},
	doi = {10.1038/s42254-021-00314-5},
	abstract = {Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-dimensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-time domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-based regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems.},
	language = {en},
	number = {6},
	urldate = {2024-02-05},
	journal = {Nature Reviews Physics},
	author = {Karniadakis, George Em and Kevrekidis, Ioannis G. and Lu, Lu and Perdikaris, Paris and Wang, Sifan and Yang, Liu},
	month = jun,
	year = {2021},
	note = {Number: 6
Publisher: Nature Publishing Group},
	keywords = {Applied mathematics, Computational science},
	pages = {422--440},
	file = {Full Text PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/86K6KKQS/Karniadakis et al. - 2021 - Physics-informed machine learning.pdf:application/pdf},
}



@article{rash_2022,
	title = {Physics-{Informed} {Neural} {Networks} ({PINNs}) for {Wave} {Propagation} and {Full} {Waveform} {Inversions}},
	volume = {127},
	copyright = {© 2022. American Geophysical Union. All Rights Reserved.},
	issn = {2169-9356},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2021JB023120},
	doi = {10.1029/2021JB023120},
	abstract = {We propose a new approach to the solution of the wave propagation and full waveform inversions (FWIs) based on a recent advance in deep learning called physics-informed neural networks (PINNs). In this study, we present an algorithm for PINNs applied to the acoustic wave equation and test the method with both forward models and FWI case studies. These synthetic case studies are designed to explore the ability of PINNs to handle varying degrees of structural complexity using both teleseismic plane waves and seismic point sources. PINNs' meshless formalism allows for a flexible implementation of the wave equation and different types of boundary conditions. For instance, our models demonstrate that PINN automatically satisfies absorbing boundary conditions, a serious computational challenge for common wave propagation solvers. Furthermore, a priori knowledge of the subsurface structure can be seamlessly encoded in PINNs' formulation. We find that the current state-of-the-art PINNs provide good results for the forward model, even though spectral element or finite difference methods are more efficient and accurate. More importantly, our results demonstrate that PINNs yield excellent results for inversions on all cases considered and with limited computational complexity. We discuss the current limitations of the method with complex velocity models as well as strategies to overcome these challenges. Using PINNs as a geophysical inversion solver offers exciting perspectives, not only for the full waveform seismic inversions, but also when dealing with other geophysical datasets (e.g., MT, gravity) as well as joint inversions because of its robust framework and simple implementation.},
	language = {en},
	number = {5},
	urldate = {2024-01-30},
	journal = {Journal of Geophysical Research: Solid Earth},
	author = {Rasht-Behesht, Majid and Huber, Christian and Shukla, Khemraj and Karniadakis, George Em},
	year = {2022},
	keywords = {deep learning, acoustic wave propagation, full waveform inversion, physics-informed neural networks},
	pages = {e2021JB023120},
	annote = {e2021JB023120 2021JB023120},
	file = {Snapshot:/home/orincon/snap/zotero-snap/common/Zotero/storage/KXLU7S7Y/2021JB023120.html:text/html;Submitted Version:/home/orincon/snap/zotero-snap/common/Zotero/storage/FSESZLFX/Rasht-Behesht et al. - 2022 - Physics-Informed Neural Networks (PINNs) for Wave .pdf:application/pdf},
}


@article{ren_seismicnet_2024,
	title = {{SeismicNet}: {Physics}-informed neural networks for seismic wave modeling in semi-infinite domain},
	volume = {295},
	issn = {0010-4655},
	shorttitle = {{SeismicNet}},
	url = {https://www.sciencedirect.com/science/article/pii/S0010465523003557},
	doi = {10.1016/j.cpc.2023.109010},
	abstract = {Recently, there has been an increasing interest in leveraging physics-informed neural networks (PINNs) for modeling dynamical systems. However, limited studies have been conducted along this horizon on seismic wave modeling tasks. A critical challenge is that these geophysical problems are typically defined in large domains (i.e., semi-infinite), which leads to high computational costs. We present a new PINN model for seismic wave modeling in semi-infinite domain without the need for labeled data. Specifically, the absorbing boundary condition is introduced into the network as a soft regularizer for handling truncated boundaries. To scale up, we consider a sequential training strategy via temporal domain decomposition to improve the scalability of the network and solution accuracy. Moreover, we design a novel surrogate modeling strategy to account for parametric loading, which estimates the wave propagation in semi-infinite domain given the seismic loading at different locations. Various numerical experiments are implemented to evaluate the performance of the proposed PINN model in the context of forward modeling of seismic wave propagation. In particular, we use diverse material distributions to test the versatility of this approach. The results demonstrate excellent solution accuracy under distinctive scenarios.},
	urldate = {2024-02-05},
	journal = {Computer Physics Communications},
	author = {Ren, Pu and Rao, Chengping and Chen, Su and Wang, Jian-Xun and Sun, Hao and Liu, Yang},
	month = feb,
	year = {2024},
	keywords = {Absorbing boundary conditions, Domain decomposition, Forward simulation, Physics-informed neural networks, Seismic wave modeling, Semi-infinite domain},
	pages = {109010},
	file = {ScienceDirect Snapshot:/home/orincon/snap/zotero-snap/common/Zotero/storage/NF8687CF/S0010465523003557.html:text/html;Versión enviada:/home/orincon/snap/zotero-snap/common/Zotero/storage/XU8HGXP9/Ren et al. - 2024 - SeismicNet Physics-informed neural networks for s.pdf:application/pdf},
}



@misc{li_fourier_2021,
	title = {Fourier {Neural} {Operator} for {Parametric} {Partial} {Differential} {Equations}},
	url = {http://arxiv.org/abs/2010.08895},
	doi = {10.48550/arXiv.2010.08895},
	abstract = {The classical development of neural networks has primarily focused on learning mappings between finite-dimensional Euclidean spaces. Recently, this has been generalized to neural operators that learn mappings between function spaces. For partial differential equations (PDEs), neural operators directly learn the mapping from any functional parametric dependence to the solution. Thus, they learn an entire family of PDEs, in contrast to classical methods which solve one instance of the equation. In this work, we formulate a new neural operator by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. We perform experiments on Burgers' equation, Darcy flow, and Navier-Stokes equation. The Fourier neural operator is the first ML-based method to successfully model turbulent flows with zero-shot super-resolution. It is up to three orders of magnitude faster compared to traditional PDE solvers. Additionally, it achieves superior accuracy compared to previous learning-based solvers under fixed resolution.},
	urldate = {2024-02-06},
	publisher = {arXiv},
	author = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
	month = may,
	year = {2021},
	note = {arXiv:2010.08895 [cs, math]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
	file = {arXiv Fulltext PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/UP6MS2FA/Li et al. - 2021 - Fourier Neural Operator for Parametric Partial Dif.pdf:application/pdf;arXiv.org Snapshot:/home/orincon/snap/zotero-snap/common/Zotero/storage/U8MH2GYE/2010.html:text/html},
}


@article{lagaris_artificial_1998,
	title = {Artificial neural networks for solving ordinary and partial differential equations},
	volume = {9},
	issn = {1941-0093},
	url = {https://ieeexplore.ieee.org/document/712178},
	doi = {10.1109/72.712178},
	abstract = {We present a method to solve initial and boundary value problems using artificial neural networks. A trial solution of the differential equation is written as a sum of two parts. The first part satisfies the initial/boundary conditions and contains no adjustable parameters. The second part is constructed so as not to affect the initial/boundary conditions. This part involves a feedforward neural network containing adjustable parameters (the weights). Hence by construction the initial/boundary conditions are satisfied and the network is trained to satisfy the differential equation. The applicability of this approach ranges from single ordinary differential equations (ODE), to systems of coupled ODE and also to partial differential equations (PDE). In this article, we illustrate the method by solving a variety of model problems and present comparisons with solutions obtained using the Galerkin finite element method for several cases of partial differential equations. With the advent of neuroprocessors and digital signal processors the method becomes particularly interesting due to the expected essential gains in the execution speed.},
	number = {5},
	urldate = {2024-02-06},
	journal = {IEEE Transactions on Neural Networks},
	author = {Lagaris, I.E. and Likas, A. and Fotiadis, D.I.},
	month = sep,
	year = {1998},
	note = {Conference Name: IEEE Transactions on Neural Networks},
	keywords = {Artificial neural networks, Boundary conditions, Boundary value problems, Differential equations, Digital signal processors, Feedforward neural networks, Finite element methods, Moment methods, Neural networks, Partial differential equations},
	pages = {987--1000},
	file = {IEEE Xplore Abstract Record:/home/orincon/snap/zotero-snap/common/Zotero/storage/XSIA9LNA/712178.html:text/html;IEEE Xplore Full Text PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/BCVSIKWB/Lagaris et al. - 1998 - Artificial neural networks for solving ordinary an.pdf:application/pdf},
}

@inproceedings{abadi_tensorflow_2016,
	title = {\{{TensorFlow}\}: {A} {System} for \{{Large}-{Scale}\} {Machine} {Learning}},
	isbn = {978-1-931971-33-1},
	shorttitle = {\{{TensorFlow}\}},
	url = {https://www.usenix.org/conference/osdi16/technical-sessions/presentation/abadi},
	language = {en},
	urldate = {2024-02-19},
	author = {Abadi, Martin and Barham, Paul and Chen, Jianmin and Chen, Zhifeng and Davis, Andy and Dean, Jeffrey and Devin, Matthieu and Ghemawat, Sanjay and Irving, Geoffrey and Isard, Michael and Kudlur, Manjunath and Levenberg, Josh and Monga, Rajat and Moore, Sherry and Murray, Derek G. and Steiner, Benoit and Tucker, Paul and Vasudevan, Vijay and Warden, Pete and Wicke, Martin and Yu, Yuan and Zheng, Xiaoqiang},
	year = {2016},
	pages = {265--283},
	file = {Full Text PDF:C\:\\Users\\osrin\\Zotero\\storage\\9RJH29DJ\\Abadi et al. - 2016 - TensorFlow A System for Large-Scale Machine L.pdf:application/pdf},
}

@article{virieux_review_2011,
author = {Virieux, Jean and Calandra, Henri and Plessix, René-Edouard},
title = {A review of the spectral, pseudo-spectral, finite-difference and finite-element modelling techniques for geophysical imaging},
journal = {Geophysical Prospecting},
volume = {59},
number = {5},
pages = {794-813},
keywords = {Electromagnetism, Imaging, Modelling, Seismic},
doi = {https://doi.org/10.1111/j.1365-2478.2011.00967.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1365-2478.2011.00967.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2478.2011.00967.x},
abstract = {ABSTRACT Modelling methods are nowadays at the heart of any geophysical interpretation approach. These are heavily relied upon by imaging techniques in elastodynamics and electromagnetism, where they are crucial for the extraction of subsurface characteristics from ever larger and denser datasets. While high-frequency or one-way approximations are very powerful and efficient, they reach their limits when complex geological settings and solutions of full equations are required at finite frequencies. A review of three important formulations is carried out here: the spectral method, which is very efficient and accurate but generally restricted to simple earth structures and often layered earth structures; the pseudo-spectral, finite-difference and finite-volume methods based on strong formulation of the partial differential equations, which are easy to implement and currently represent a good compromise between accuracy, efficiency and flexibility and the continuous or discontinuous Galerkin finite-element methods that are based on the weak formulation, which lead to more accurate earth representations and therefore to more accurate solutions, although with higher computational costs and more complex use. The choice between these different approaches is still difficult and depends on the applications. Guidelines are given here through discussion of the requirements for imaging/inversion.},
year = {2011}
}



@inproceedings{paszke_pytorch_2019,
	title = {{PyTorch}: {An} {Imperative} {Style}, {High}-{Performance} {Deep} {Learning} {Library}},
	volume = {32},
	shorttitle = {{PyTorch}},
	url = {https://proceedings.neurips.cc/paper_files/paper/2019/hash/bdbca288fee7f92f2bfa9f7012727740-Abstract.html},
	abstract = {Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it was designed from first principles to support an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs.
In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance.
We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several commonly used benchmarks.},
	urldate = {2024-02-19},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
	year = {2019},
	file = {Full Text PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/FAT3ZNYK/Paszke et al. - 2019 - PyTorch An Imperative Style, High-Performance Dee.pdf:application/pdf},
}

@article{cuomo_scientific_2022,
	title = {Scientific {Machine} {Learning} {Through} {Physics}–{Informed} {Neural} {Networks}: {Where} we are and {What}’s {Next}},
	volume = {92},
	issn = {1573-7691},
	shorttitle = {Scientific {Machine} {Learning} {Through} {Physics}–{Informed} {Neural} {Networks}},
	url = {https://doi.org/10.1007/s10915-022-01939-z},
	doi = {10.1007/s10915-022-01939-z},
	abstract = {Physics-Informed Neural Networks (PINN) are neural networks (NNs) that encode model equations, like Partial Differential Equations (PDE), as a component of the neural network itself. PINNs are nowadays used to solve PDEs, fractional equations, integral-differential equations, and stochastic PDEs. This novel methodology has arisen as a multi-task learning framework in which a NN must fit observed data while reducing a PDE residual. This article provides a comprehensive review of the literature on PINNs: while the primary goal of the study was to characterize these networks and their related advantages and disadvantages. The review also attempts to incorporate publications on a broader range of collocation-based physics informed neural networks, which stars form the vanilla PINN, as well as many other variants, such as physics-constrained neural networks (PCNN), variational hp-VPINN, and conservative PINN (CPINN). The study indicates that most research has focused on customizing the PINN through different activation functions, gradient optimization techniques, neural network structures, and loss function structures. Despite the wide range of applications for which PINNs have been used, by demonstrating their ability to be more feasible in some contexts than classical numerical techniques like Finite Element Method (FEM), advancements are still possible, most notably theoretical issues that remain unresolved.},
	language = {en},
	number = {3},
	urldate = {2024-02-19},
	journal = {Journal of Scientific Computing},
	author = {Cuomo, Salvatore and Di Cola, Vincenzo Schiano and Giampaolo, Fabio and Rozza, Gianluigi and Raissi, Maziar and Piccialli, Francesco},
	month = jul,
	year = {2022},
	keywords = {Numerical methods, Uncertainty, Deep Neural Networks, Nonlinear equations, Partial Differential Equations, Physics–Informed Neural Networks, Scientific Machine Learning},
	pages = {88},
	file = {Exported Items.bib:/home/orincon/snap/zotero-snap/common/Zotero/storage/FF7PZ4ZC/Exported Items.bib:text/x-bibtex;Full Text PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/K6R2UNBH/Cuomo et al. - 2022 - Scientific Machine Learning Through Physics–Inform.pdf:application/pdf},
}

@article{paszke_automatic_2017,
	title = {Automatic differentiation in {PyTorch}},
	abstract = {In this article, we describe an automatic differentiation module of PyTorch — a library designed to enable rapid research on machine learning models. It builds upon a few projects, most notably Lua Torch, Chainer, and HIPS Autograd [4], and provides a high performance environment with easy access to automatic differentiation of models executed on different devices (CPU and GPU). To make prototyping easier, PyTorch does not follow the symbolic approach used in many other deep learning frameworks, but focuses on differentiation of purely imperative programs, with a focus on extensibility and low overhead. Note that this preprint is a draft of certain sections from an upcoming paper covering all PyTorch features.},
	language = {en},
	author = {Paszke, Adam and Gross, Sam and Chintala, Soumith and Chanan, Gregory and Yang, Edward and DeVito, Zachary and Lin, Zeming and Desmaison, Alban and Antiga, Luca and Lerer, Adam},
	year = {2017},
	file = {Paszke et al. - Automatic differentiation in PyTorch.pdf:/home/orincon/snap/zotero-snap/common/Zotero/storage/C4UMT8RF/Paszke et al. - Automatic differentiation in PyTorch.pdf:application/pdf},
}

@article{alterman_propagation_1968,
	title = {Propagation of elastic waves in layered media by finite difference methods},
	volume = {58},
	issn = {0037-1106},
	url = {https://doi.org/10.1785/BSSA0580010367},
	doi = {10.1785/BSSA0580010367},
	abstract = {A finite difference equation formulation for the equations of elasticity is presented and applied to the problem of a layered half-space with a buried point source emitting a compressional pulse. Complete theoretical seismograms for the horizontal and vertical components of displacement are obtained. The results for a specific case are compared with those found by a completely different method in order to check the validity of the finite difference methods. The agreement is excellent. The effect of different mesh sizes on the theoretical seismograms is studied next and a suitable grid system selected for the applications that follow. The development of Rayleigh waves on the surface of a half-space and the change of the Rayleigh wave with depth and pulse width are examined. The problem of a layered half-space with a high velocity bottom is considered and the refraction arrivals on the surface and on the interface are studied. The problem of interface waves on the surface separating two semiinfinite media is also examined. Interface waves are found when the physical parameters lie both inside and outside the region determined by the Stoneley equation. Finally, a series of theoretical seismograms for a layered half-space showing the variation of the surface waves as a function of depth and of the density in the lower medium is presented.},
	number = {1},
	urldate = {2024-02-20},
	journal = {Bulletin of the Seismological Society of America},
	author = {Alterman, Z. and Karal, Jr., F. C.},
	month = feb,
	year = {1968},
	pages = {367--398},
	file = {Snapshot:/home/orincon/snap/zotero-snap/common/Zotero/storage/B4TFM55L/Propagation-of-elastic-waves-in-layered-media-by.html:text/html},
}

@article{madariaga_dynamics_1976,
	title = {Dynamics of an expanding circular fault},
	volume = {66},
	issn = {0037-1106},
	url = {https://doi.org/10.1785/BSSA0660030639},
	doi = {10.1785/BSSA0660030639},
	abstract = {We study a plane circular model of a frictional fault using numerical methods. The model is dynamic since we specify the effective stress at the fault. In one model we assume that the fault appears instantaneously in the medium; in another, that the rupture nucleates at the center and that rupture proceeds at constant subsonic velocity until it suddenly stops. The total source slip is larger at the center and the rise time is also longer at the center of the fault. The dynamic slip overshoots the static slip by 15 to 35 per cent. As a consequence, the stress drop is larger than the effective stress and the apparent stress is less than one half the effective stress.The far-field radiation is discussed in detail. We distinguish three spectral regions. First, the usual constant low-frequency level. Second, an intermediate region controlled by the fault size and, finally, the high-frequency asymptote. The central region includes the corner frequency and is quite complicated. The corner frequency is shown to be inversely proportional to the width of the far-field displacement pulse which, in turn, is related to the time lag between the stopping phases. The average corner frequency of S waves v0s is related to the final source radius, a, by v0s = 0.21 β/α. The corner frequency of P waves is larger than v0s by an average factor of 1.5.},
	number = {3},
	urldate = {2024-02-20},
	journal = {Bulletin of the Seismological Society of America},
	author = {Madariaga, Raul},
	month = jun,
	year = {1976},
	pages = {639--666},
	file = {Snapshot:/home/orincon/snap/zotero-snap/common/Zotero/storage/U4QVB82I/Dynamics-of-an-expanding-circular-fault.html:text/html},
}

@article{frankel_three-dimensional_1992,
	title = {A three-dimensional simulation of seismic waves in the {Santa} {Clara} {Valley}, {California}, from a {Loma} {Prieta} aftershock},
	volume = {82},
	issn = {0037-1106},
	url = {https://doi.org/10.1785/BSSA0820052045},
	doi = {10.1785/BSSA0820052045},
	abstract = {The finite-difference method is used to propagate elastic waves through a 3-D model of the Santa Clara Valley, an alluvium-filled basin that underlies the city of San Jose, California. The model was based on depth to bedrock information from water wells in the area. The simulation corresponded to a region 30 (east-west) by 22 (north-south) by 6 (depth) km and contained about 4 million grid points. Synthetic seismograms from the simulation are accurate at frequencies up to 1 Hz. Motions from a magnitude 4.4 aftershock of the Loma Prieta earthquake were modeled. Snapshots of ground motion and synthetic seismograms from the simulation are presented. The simulation illustrates S-to-surface-wave conversion at the edges of the basin and the large amplitude and long duration of ground motion in the basin compared to the surrounding rock. Love waves produced at the edge of the basin are the largest arrivals in the transverse synthetics. Because of the slow group velocity of the Love waves, sites near the center of the basin have longer durations of significant motions than basin sites near the valley edges. Sites near the center of the basin also show larger peak amplitudes on the transverse component. Array analysis of the synthetic seismograms indicates that Love waves tend to propagate parallel to the eastern and western edges of the valley. Rayleigh waves are produced along the southern margin of the basin from incident S waves. Large radial motions occur where a Rayleigh wave impinges on the northeast margin of the valley. Some Rayleigh waves travel westward across the basin, after being scattered from the eastern edge of the valley. Synthetic seismograms from the simulation have similar peak amplitudes as seismograms recorded by the Sunnyvale dense array for this aftershock, although the duration of the tranverse component is not matched by the synthetic seismogram, using this basin model. The simulation indicates that the Love waves observed on the actual seismograms were produced by conversion of incident S waves at the southern margin of the Santa Clara Valley. 2-D simulations show how the S-to-Love-wave conversion is affected by the angle of incidence of the S wave and the sharpness of the velocity transition between the alluvium and bedrock. As more accurate basin models are developed, 3-D simulations should become valuable for predicting ground motions in sedimentary basins for future large earthquakes.},
	number = {5},
	urldate = {2024-02-20},
	journal = {Bulletin of the Seismological Society of America},
	author = {Frankel, Arthur and Vidale, John},
	month = oct,
	year = {1992},
	pages = {2045--2074},
	file = {Snapshot:/home/orincon/snap/zotero-snap/common/Zotero/storage/DI8FV8DW/A-three-dimensional-simulation-of-seismic-waves-in.html:text/html},
}

@inproceedings{lehmann_fourier_2023,
	title = {Fourier {Neural} {Operator} {Surrogate} {Model} to {Predict} {3D} {Seismic} {Waves} {Propagation}},
	url = {http://arxiv.org/abs/2304.10242},
	doi = {10.7712/120223.10339.20362},
	abstract = {With the recent rise of neural operators, scientific machine learning offers new solutions to quantify uncertainties associated with high-fidelity numerical simulations. Traditional neural networks, such as Convolutional Neural Networks (CNN) or Physics-Informed Neural Networks (PINN), are restricted to the prediction of solutions in a predefined configuration. With neural operators, one can learn the general solution of Partial Differential Equations, such as the elastic wave equation, with varying parameters. There have been very few applications of neural operators in seismology. All of them were limited to two-dimensional settings, although the importance of three-dimensional (3D) effects is well known. In this work, we apply the Fourier Neural Operator (FNO) to predict ground motion time series from a 3D geological description. We used a high-fidelity simulation code, SEM3D, to build an extensive database of ground motions generated by 30,000 different geologies. With this database, we show that the FNO can produce accurate ground motion even when the underlying geology exhibits large heterogeneities. Intensity measures at moderate and large periods are especially well reproduced. We present the first seismological application of Fourier Neural Operators in 3D. Thanks to the generalizability of our database, we believe that our model can be used to assess the influence of geological features such as sedimentary basins on ground motion, which is paramount to evaluating site effects.},
	urldate = {2024-02-12},
	author = {Lehmann, Fanny and Gatti, Filippo and Bertin, Michaël and Clouteau, Didier},
	year = {2023},
	note = {arXiv:2304.10242 [physics]},
	keywords = {Physics - Geophysics, Computer Science - Machine Learning},
	pages = {297--310},
	file = {arXiv.org Snapshot:/home/orincon/snap/zotero-snap/common/Zotero/storage/C2LKZN4Y/2304.html:text/html;Full Text PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/JV8LF5IV/Lehmann et al. - 2023 - Fourier Neural Operator Surrogate Model to Predict.pdf:application/pdf},
}

@article{baydin_automatic_2017,
	title = {Automatic differentiation in machine learning: a survey},
	volume = {18},
	issn = {1532-4435},
	shorttitle = {Automatic differentiation in machine learning},
	abstract = {Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic differentiation (AD), also called algorithmic differentiation or simply "auto-diff", is a family of techniques similar to but more general than backpropagation for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. AD is a small but established field with applications in areas including computational uid dynamics, atmospheric sciences, and engineering design optimization. Until very recently, the fields of machine learning and AD have largely been unaware of each other and, in some cases, have independently discovered each other's results. Despite its relevance, general-purpose AD has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names "dynamic computational graphs" and "differentiable programming". We survey the intersection of AD and machine learning, cover applications where AD has direct relevance, and address the main implementation techniques. By precisely defining the main differentiation techniques and their interrelationships, we aim to bring clarity to the usage of the terms "autodiff", "automatic differentiation", and "symbolic differentiation" as these are encountered more and more in machine learning settings.},
	number = {1},
	journal = {The Journal of Machine Learning Research},
	author = {Baydin, Atılım Günes and Pearlmutter, Barak A. and Radul, Alexey Andreyevich and Siskind, Jeffrey Mark},
	month = jan,
	year = {2017},
	keywords = {backpropagation, differentiable programming},
	pages = {5595--5637},
	file = {Full Text PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/TV96P8ND/Baydin et al. - 2017 - Automatic differentiation in machine learning a s.pdf:application/pdf},
}

 @article{lecun_deep_2015,
	title = {Deep learning},
	volume = {521},
	issn = {1476-4687},
	url = {https://doi.org/10.1038/nature14539},
	doi = {10.1038/nature14539},
	abstract = {Deep learning allows computational models that are composed of multiple processing layers to learn representations of data with multiple levels of abstraction. These methods have dramatically improved the state-of-the-art in speech recognition, visual object recognition, object detection and many other domains such as drug discovery and genomics. Deep learning discovers intricate structure in large data sets by using the backpropagation algorithm to indicate how a machine should change its internal parameters that are used to compute the representation in each layer from the representation in the previous layer. Deep convolutional nets have brought about breakthroughs in processing images, video, speech and audio, whereas recurrent nets have shone light on sequential data such as text and speech.},
	number = {7553},
	journal = {Nature},
	author = {LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
	month = may,
	year = {2015},
	pages = {436--444},
}

@book{goodfellow_deep_2016,
	title = {Deep {Learning}},
	isbn = {978-0-262-33737-3},
	abstract = {An introduction to a broad range of topics in deep learning, covering mathematical and conceptual background, deep learning techniques used in industry, and research perspectives.“Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.”—Elon Musk, cochair of OpenAI; cofounder and CEO of Tesla and SpaceXDeep learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.},
	language = {en},
	publisher = {MIT Press},
	author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
	month = nov,
	year = {2016},
	note = {Google-Books-ID: omivDQAAQBAJ},
	keywords = {Computers / Artificial Intelligence / General, Computers / Computer Science, Computers / Data Science / Machine Learning},
}


@article{lino_current_2023,
	title = {Current and emerging deep-learning methods for the simulation of fluid dynamics},
	volume = {479},
	url = {https://royalsocietypublishing.org/doi/full/10.1098/rspa.2023.0058},
	doi = {10.1098/rspa.2023.0058},
	abstract = {Over the last decade, deep learning (DL), a branch of machine learning, has experienced rapid progress. Powerful tools for tasks that have been traditionally complex to automate have been developed, such as image synthesis and natural language processing. In the context of simulating fluid dynamics, this has led to a series of novel DL methods for replacing or augmenting conventional numerical solvers. We broadly classify these methods into physics- and data-driven methods. Physics-driven methods, generally, tune a DL model to provide an analytical and differentiable solution to a given fluid dynamics problem by minimizing the residuals of the governing partial differential equations. Data-driven methods provide a fast and approximate solution to any fluid dynamics problem that shares some physical properties with the observations used when tuning the DL model’s parameters. Meanwhile, the symbiosis of numerical solvers and DL has led to promising results in turbulence modelling and accelerating iterative solvers. However, these methods present some challenges. Exclusively data-driven flow simulators often suffer from poor extrapolation, error accumulation in time-dependent simulations, as well as difficulties in training against turbulent flows. Substantial effort is, therefore, being invested into approaches that may improve the current state of the art.},
	number = {2275},
	urldate = {2024-02-19},
	journal = {Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	author = {Lino, Mario and Fotiadis, Stathi and Bharath, Anil A. and Cantwell, Chris D.},
	month = jul,
	year = {2023},
	note = {Publisher: Royal Society},
	keywords = {computational fluid dynamics, data-driven fluid dynamics, deep learning, deep neural networks, physics-informed neural networks, turbulence modelling},
	pages = {20230058},
	file = {Full Text PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/YECXYB3L/Lino et al. - 2023 - Current and emerging deep-learning methods for the.pdf:application/pdf},
}

@article{deng_physics-informed_2023,
	title = {Physics-informed machine learning in prognostics and health management: {State} of the art and challenges},
	volume = {124},
	issn = {0307-904X},
	shorttitle = {Physics-informed machine learning in prognostics and health management},
	url = {https://www.sciencedirect.com/science/article/pii/S0307904X23003086},
	doi = {10.1016/j.apm.2023.07.011},
	abstract = {Prognostics and health management (PHM) plays a constructive role in the equipment’s entire life health service. It has long benefited from intensive research into physics modeling and machine learning methods. However, in practice, the existing solutions often encounter difficulties caused by sparse data \& incomplete system failure knowledge. Pure machine learning or physics-based methods can sometimes be infeasible in such situations. As a result, there has been a growing interest in developing physics-informed machine learning (PIML) models which allow incorporating different forms of physics knowledge at different positions of the machine learning pipeline. This combination provides significant assistance for detection, diagnostic, and prognostics. However, to the best of our knowledge, the bibliometrics analyses and the comprehensive review of the existing research concerning PIML in PHM remain vacant. Our review is therefore dedicated to filling these gaps. We synthesize the concept of PIML in PHM, and propose a taxonomy of PIML approaches from the perspective of “Expression forms of informed knowledge” and “Knowledge informed methods”. The findings and discussions presented in this paper enable us to clarify the current state of the art and the emerging opportunities of PIML approaches, especially for building PHM systems that can work under the “small data and scarce physics knowledge” paradigm.},
	urldate = {2024-02-19},
	journal = {Applied Mathematical Modelling},
	author = {Deng, Weikun and Nguyen, Khanh T. P. and Medjaher, Kamal and Gogu, Christian and Morio, Jérôme},
	month = dec,
	year = {2023},
	keywords = {Knowledge, Physics-constraint learning, Physics-embedded algorithm structure, Physics-informed input space, Physics-informed machine learning, Prognostics and health management},
	pages = {325--352},
	file = {1-s2.0-S0307904X23003086-main.pdf:/home/orincon/snap/zotero-snap/common/Zotero/storage/KWUJ2MBG/1-s2.0-S0307904X23003086-main.pdf:application/pdf;Exported Items.bib:/home/orincon/snap/zotero-snap/common/Zotero/storage/ALY9JBHI/Exported Items.bib:text/x-bibtex;ScienceDirect Snapshot:/home/orincon/snap/zotero-snap/common/Zotero/storage/YA2H5WZN/S0307904X23003086.html:text/html},
}

@article{vadyala_review_2022,
	title = {A review of physics-based machine learning in civil engineering},
	volume = {13},
	issn = {2590-1230},
	url = {https://www.sciencedirect.com/science/article/pii/S2590123021001171},
	doi = {10.1016/j.rineng.2021.100316},
	abstract = {The recent development of machine learning (ML) and Deep Learning (DL) increases the opportunities in all the sectors. ML is a significant tool that can be applied across many disciplines, but its direct application to civil engineering problems can be challenging. ML for civil engineering applications that are simulated in the lab often fail in real-world tests. This is usually attributed to a data mismatch between the data used to train and test the ML model and the data it encounters in the real world, a phenomenon known as data shift. However, a physics-based ML model integrates data, partial differential equations (PDEs), and mathematical models to solve data shift problems. Physics-based ML models are trained to solve supervised learning tasks while respecting any given laws of physics described by general nonlinear equations. Physics-based ML, which takes center stage across many science disciplines, plays an important role in fluid dynamics, quantum mechanics, computational resources, and data storage. This paper reviews the history of physics-based ML and its application in civil engineering.},
	urldate = {2024-02-19},
	journal = {Results in Engineering},
	author = {Vadyala, Shashank Reddy and Betgeri, Sai Nethra and Matthews, John C. and Matthews, Elizabeth},
	month = mar,
	year = {2022},
	keywords = {Civil engineering, Deep neural network, Machine learning, Physics-based machine learning},
	pages = {100316},
	file = {ScienceDirect Snapshot:/home/orincon/snap/zotero-snap/common/Zotero/storage/92SPAILV/S2590123021001171.html:text/html;Submitted Version:/home/orincon/snap/zotero-snap/common/Zotero/storage/G8U9TL5E/Vadyala et al. - 2022 - A review of physics-based machine learning in civi.pdf:application/pdf},
}

@article{blechschmidt_three_2021,
	title = {Three ways to solve partial differential equations with neural networks — {A} review},
	volume = {44},
	copyright = {© 2021 The Authors. GAMM - Mitteilungen published by Wiley-VCH GmbH.},
	issn = {1522-2608},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/gamm.202100006},
	doi = {10.1002/gamm.202100006},
	abstract = {Neural networks are increasingly used to construct numerical solution methods for partial differential equations. In this expository review, we introduce and contrast three important recent approaches attractive in their simplicity and their suitability for high-dimensional problems: physics-informed neural networks, methods based on the Feynman–Kac formula and methods based on the solution of backward stochastic differential equations. The article is accompanied by a suite of expository software in the form of Jupyter notebooks in which each basic methodology is explained step by step, allowing for a quick assimilation and experimentation. An extensive bibliography summarizes the state of the art.},
	language = {en},
	number = {2},
	urldate = {2024-02-22},
	journal = {GAMM-Mitteilungen},
	author = {Blechschmidt, Jan and Ernst, Oliver G.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/gamm.202100006},
	keywords = {backward differential equation, curse of dimensionality, Feynman–Kac, Hamilton–Jacobi–Bellman equations, neural networks, partial differential equation, PINN, stochastic process},
	pages = {e202100006},
	file = {Full Text PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/9BL4ZG4Y/Blechschmidt and Ernst - 2021 - Three ways to solve partial differential equations.pdf:application/pdf},
}

@misc{li_neural_2020,
	title = {Neural {Operator}: {Graph} {Kernel} {Network} for {Partial} {Differential} {Equations}},
	shorttitle = {Neural {Operator}},
	url = {http://arxiv.org/abs/2003.03485},
	doi = {10.48550/arXiv.2003.03485},
	abstract = {The classical development of neural networks has been primarily for mappings between a finite-dimensional Euclidean space and a set of classes, or between two finite-dimensional Euclidean spaces. The purpose of this work is to generalize neural networks so that they can learn mappings between infinite-dimensional spaces (operators). The key innovation in our work is that a single set of network parameters, within a carefully designed network architecture, may be used to describe mappings between infinite-dimensional spaces and between different finite-dimensional approximations of those spaces. We formulate approximation of the infinite-dimensional mapping by composing nonlinear activation functions and a class of integral operators. The kernel integration is computed by message passing on graph networks. This approach has substantial practical consequences which we will illustrate in the context of mappings between input data to partial differential equations (PDEs) and their solutions. In this context, such learned networks can generalize among different approximation methods for the PDE (such as finite difference or finite element methods) and among approximations corresponding to different underlying levels of resolution and discretization. Experiments confirm that the proposed graph kernel network does have the desired properties and show competitive performance compared to the state of the art solvers.},
	urldate = {2024-02-22},
	publisher = {arXiv},
	author = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
	month = mar,
	year = {2020},
	note = {arXiv:2003.03485 [cs, math, stat]},
	keywords = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/62G8G5RY/Li et al. - 2020 - Neural Operator Graph Kernel Network for Partial .pdf:application/pdf;arXiv.org Snapshot:/home/orincon/snap/zotero-snap/common/Zotero/storage/KFV6JKE2/2003.html:text/html},
}


@article{lin_physics-guided_2023,
	title = {Physics-{Guided} {Data}-{Driven} {Seismic} {Inversion}: {Recent} progress and future opportunities in full-waveform inversion},
	volume = {40},
	issn = {1558-0792},
	shorttitle = {Physics-{Guided} {Data}-{Driven} {Seismic} {Inversion}},
	url = {https://ieeexplore.ieee.org/document/10004771},
	doi = {10.1109/MSP.2022.3217658},
	abstract = {The goal of seismic inversion is to obtain subsurface properties from surface measurements. Seismic images have proven valuable, even crucial, for a variety of applications, including subsurface energy exploration, earthquake early warning, carbon capture and sequestration, estimating pathways of subsurface contaminant transport, etc. These subsurface properties (such as wave speed, density, and elastic velocities) influence the transmission of seismic waves through the subsurface media, and well-understood physics models (so-called “forward models”) can be used to predict what surface measurements would be made for any given subsurface configuration.},
	number = {1},
	urldate = {2024-02-19},
	journal = {IEEE Signal Processing Magazine},
	author = {Lin, Youzuo and Theiler, James and Wohlberg, Brendt},
	month = jan,
	year = {2023},
	note = {Conference Name: IEEE Signal Processing Magazine},
	keywords = {Earthquakes, Measurement uncertainty, Predictive models, Seismic measurements, Surface contamination, Surface waves, Uncertainty},
	pages = {115--133},
	file = {IEEE Xplore Abstract Record:/home/orincon/snap/zotero-snap/common/Zotero/storage/Q6UVSUCJ/10004771.html:text/html;IEEE Xplore Full Text PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/UT5WHMF4/Lin et al. - 2023 - Physics-Guided Data-Driven Seismic Inversion Rece.pdf:application/pdf},
}

@article{yu_deep_2021,
	title = {Deep {Learning} for {Geophysics}: {Current} and {Future} {Trends}},
	volume = {59},
	copyright = {© 2021. The Authors.},
	issn = {1944-9208},
	shorttitle = {Deep {Learning} for {Geophysics}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1029/2021RG000742},
	doi = {10.1029/2021RG000742},
	abstract = {Recently deep learning (DL), as a new data-driven technique compared to conventional approaches, has attracted increasing attention in geophysical community, resulting in many opportunities and challenges. DL was proven to have the potential to predict complex system states accurately and relieve the “curse of dimensionality” in large temporal and spatial geophysical applications. We address the basic concepts, state-of-the-art literature, and future trends by reviewing DL approaches in various geosciences scenarios. Exploration geophysics, earthquakes, and remote sensing are the main focuses. More applications, including Earth structure, water resources, atmospheric science, and space science, are also reviewed. Additionally, the difficulties of applying DL in the geophysical community are discussed. The trends of DL in geophysics in recent years are analyzed. Several promising directions are provided for future research involving DL in geophysics, such as unsupervised learning, transfer learning, multimodal DL, federated learning, uncertainty estimation, and active learning. A coding tutorial and a summary of tips for rapidly exploring DL are presented for beginners and interested readers of geophysics.},
	language = {en},
	number = {3},
	urldate = {2024-02-21},
	journal = {Reviews of Geophysics},
	author = {Yu, Siwei and Ma, Jianwei},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1029/2021RG000742},
	keywords = {artificial intelligence, data-driven geophysics, deep learning, dictionary learning, exploration geophysics, machine learning},
	pages = {e2021RG000742},
	file = {Full Text PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/I3DHTHK2/Yu y Ma - 2021 - Deep Learning for Geophysics Current and Future T.pdf:application/pdf;Snapshot:/home/orincon/snap/zotero-snap/common/Zotero/storage/C4XGMN5P/2021RG000742.html:text/html},
}


@misc{kharazmi_variational_2019,
	title = {Variational {Physics}-{Informed} {Neural} {Networks} {For} {Solving} {Partial} {Differential} {Equations}},
	url = {http://arxiv.org/abs/1912.00873},
	doi = {10.48550/arXiv.1912.00873},
	abstract = {Physics-informed neural networks (PINNs) [31] use automatic differentiation to solve partial differential equations (PDEs) by penalizing the PDE in the loss function at a random set of points in the domain of interest. Here, we develop a Petrov-Galerkin version of PINNs based on the nonlinear approximation of deep neural networks (DNNs) by selecting the \{{\textbackslash}em trial space\} to be the space of neural networks and the \{{\textbackslash}em test space\} to be the space of Legendre polynomials. We formulate the {\textbackslash}textit\{variational residual\} of the PDE using the DNN approximation by incorporating the variational form of the problem into the loss function of the network and construct a {\textbackslash}textit\{variational physics-informed neural network\} (VPINN). By integrating by parts the integrand in the variational form, we lower the order of the differential operators represented by the neural networks, hence effectively reducing the training cost in VPINNs while increasing their accuracy compared to PINNs that essentially employ delta test functions. For shallow networks with one hidden layer, we analytically obtain explicit forms of the {\textbackslash}textit\{variational residual\}. We demonstrate the performance of the new formulation for several examples that show clear advantages of VPINNs over PINNs in terms of both accuracy and speed.},
	urldate = {2024-02-26},
	publisher = {arXiv},
	author = {Kharazmi, E. and Zhang, Z. and Karniadakis, G. E.},
	month = nov,
	year = {2019},
	note = {arXiv:1912.00873 [physics, stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing, Mathematics - Numerical Analysis, Physics - Computational Physics, Statistics - Machine Learning},
	file = {arXiv Fulltext PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/FLU83LXQ/Kharazmi et al. - 2019 - Variational Physics-Informed Neural Networks For S.pdf:application/pdf;arXiv.org Snapshot:/home/orincon/snap/zotero-snap/common/Zotero/storage/LPYQ8F4E/1912.html:text/html},
}


@article{wu_helmholtz-equation_2023,
	title = {Helmholtz-equation solution in nonsmooth media by a physics-informed neural network incorporating quadratic terms and a perfectly matching layer condition},
	volume = {88},
	issn = {0016-8033},
	url = {https://doi.org/10.1190/geo2022-0479.1},
	doi = {10.1190/geo2022-0479.1},
	abstract = {Frequency-domain simulation of seismic waves plays an important role in seismic inversion, but it remains challenging in large models. The recently proposed physics-informed neural network (PINN), as an effective deep-learning method, has achieved successful applications in solving a wide range of partial differential equations (PDEs), and there is still room for improvement on this front. For example, PINN can lead to inaccurate solutions when PDE coefficients are nonsmooth and describe structurally complex media. Thus, we solve the acoustic and visco-acoustic scattered-field (Lippmann-Schwinger) wave equation in the frequency domain with PINN instead of the wave equation to remove the source singularity. We first illustrate that nonsmooth velocity models lead to inaccurate wavefields when no boundary conditions are implemented in the loss function. Then, we add the perfectly matched layer (PML) conditions in the loss function to better couple the real and imaginary parts of the wavefield. Moreover, we design new neurons by replacing the classical affine function with a quadratic function in the argument of the activation function to better capture the nonsmooth features of the wavefields. We find that the PML condition and the quadratic functions improve the results including handling attenuation and discuss the reason for this improvement. We also illustrate that a network trained to predict a wavefield for a specific medium can be used as an initial model of the neural network for predicting other wavefields corresponding to PDE-coefficient alterations and improving the convergence speed accordingly. This pretraining strategy should find applications in iterative full-waveform inversion and time-lag target-oriented imaging when the model perturbation between two consecutive iterations or two consecutive experiments is small.},
	number = {4},
	urldate = {2024-02-28},
	journal = {Geophysics},
	author = {Wu, Yanqi and Aghamiry, Hossein S. and Operto, Stephane and Ma, Jianwei},
	month = jun,
	year = {2023},
	pages = {T185--T202},
	file = {Snapshot:/home/orincon/snap/zotero-snap/common/Zotero/storage/FZ2NRDBI/Helmholtz-equation-solution-in-nonsmooth-media-by.html:text/html},
}


@inproceedings{alkhadhr_modeling_2021,
	title = {Modeling of the {Forward} {Wave} {Propagation} {Using} {Physics}-{Informed} {Neural} {Networks}},
	url = {https://ieeexplore.ieee.org/abstract/document/9593574},
	doi = {10.1109/IUS52206.2021.9593574},
	abstract = {Partial Differential Equations (PDEs) are used in modeling problems in nature and are commonly solved using classical methods like Finite Element Method (FEM), Finite Volume Method (FVM), or Finite Difference Method (FDM). However, solving high-dimensional PDEs has been notoriously difficult due to the Curse of Dimensionality (CoD). Among the pool of hyperbolic PDEs, the wave equation in particular is the base for modeling various clinical applications and designing many solutions in the medical fields of therapeutic and diagnostic ultrasound. This draws attention to the importance of accurate and efficient simulation. In recent years, deep neural networks have been proposed to predict numerical solutions of PDEs. Within that context, Physics-Informed Neural Networks (PINNs) have surfaced as a powerful tool for modeling PDEs. We simulate a linear wave equation with a single time-dependent sinusoidal source function e.g.: sin (π t) using PINNs to model one of the most fundamental modeling equations in medical ultrasound applications. Results achieved are validated by an FDM solution with the same problem setup. After training, the PINN prediction takes an average time 47\% of the FDM time performed by MATLAB for the same simulation metrics (IC, BC, and domain range) on the same machine. Being a mesh-free approach, PINNs overcome the CoD which is one of the main challenges in traditional modeling methods.},
	urldate = {2024-02-26},
	booktitle = {2021 {IEEE} {International} {Ultrasonics} {Symposium} ({IUS})},
	author = {Alkhadhr, Shaikhah and Liu, Xilun and Almekkawy, Mohamed},
	month = sep,
	year = {2021},
	note = {ISSN: 1948-5727},
	keywords = {Propagation, Neural networks, Wave Equation, Forward Problem, Frequency division multiplexing, Mathematical models, Numerical Modelling, Numerical models, Physics-Informed Neural Networks, Training, Ultrasonic imaging},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:/home/orincon/snap/zotero-snap/common/Zotero/storage/8DVPJYJJ/9593574.html:text/html;IEEE Xplore Full Text PDF:/home/orincon/snap/zotero-snap/common/Zotero/storage/XXV3B86F/Alkhadhr et al. - 2021 - Modeling of the Forward Wave Propagation Using Phy.pdf:application/pdf},
}


@article{alkhadhr_wave_2023,
	title = {Wave {Equation} {Modeling} via {Physics}-{Informed} {Neural} {Networks}: {Models} of {Soft} and {Hard} {Constraints} for {Initial} and {Boundary} {Conditions}},
	volume = {23},
	issn = {1424-8220},
	shorttitle = {Wave {Equation} {Modeling} via {Physics}-{Informed} {Neural} {Networks}},
	doi = {10.3390/s23052792},
	abstract = {Therapeutic ultrasound waves are the main instruments used in many noninvasive clinical procedures. They are continuously transforming medical treatments through mechanical and thermal effects. To allow for effective and safe delivery of ultrasound waves, numerical modeling methods such as the Finite Difference Method (FDM) and the Finite Element Method (FEM) are used. However, modeling the acoustic wave equation can result in several computational complications. In this work, we study the accuracy of using Physics-Informed Neural Networks (PINNs) to solve the wave equation when applying different combinations of initial and boundary conditions (ICs and BCs) constraints. By exploiting the mesh-free nature of PINNs and their prediction speed, we specifically model the wave equation with a continuous time-dependent point source function. Four main models are designed and studied to monitor the effects of soft or hard constraints on the prediction accuracy and performance. The predicted solutions in all the models were compared to an FDM solution for prediction error estimation. The trials of this work reveal that the wave equation modeled by a PINN with soft IC and BC (soft–soft) constraints reflects the lowest prediction error among the four combinations of constraints. © 2023 by the authors.},
	language = {English},
	number = {5},
	journal = {Sensors},
	author = {Alkhadhr, S. and Almekkawy, M.},
	year = {2023},
	keywords = {physics-informed neural networks, numerical modeling, ultrasound therapeutics, wave equation},
	file = {Texto completo:/home/orincon/snap/zotero-snap/common/Zotero/storage/NPF85GKG/Alkhadhr y Almekkawy - 2023 - Wave Equation Modeling via Physics-Informed Neural.pdf:application/pdf},
}